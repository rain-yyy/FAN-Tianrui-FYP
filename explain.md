# Project Wiki Generation API 技术文档与路线图

## 1. 项目概述

本项目是一个自动化的 Wiki 生成系统，旨在将复杂的 Git 仓库（如 GitHub 上的项目）自动分析并转化为结构化的 Wiki 文档。系统通过静态代码分析、代码知识图谱构建、GraphRAG 社区发现以及大语言模型（LLM）的理解能力，自动生成项目的功能描述、架构图（Mermaid）以及各模块的详细解释。

## 2. API 路线图 (Roadmap)

整个 Wiki 生成流程遵循**"异步任务处理 + 云端持久化"**的设计模式，确保能够处理耗时较长的 AI 生成任务。

### 核心工作流：

1. **任务触发**: 用户提交仓库 URL。
2. **环境准备**: 后端异步克隆仓库并加载配置文件。
3. **静态分析与代码理解**:
   * 生成完整的文件树（File Tree）。
   * **构建代码知识图谱 (Code Knowledge Graph)**:
     - 使用 Tree-sitter 解析代码文件（支持 Python、JavaScript、TypeScript、TSX 等）
     - 提取文件、类、函数等代码实体作为节点
     - 提取调用关系（calls）、包含关系（contains）等作为边
     - 构建有向图（NetworkX DiGraph）表示代码结构
   * **社区发现与摘要生成 (GraphRAG)**:
     - 将代码图谱转换为无向图
     - 运行 Leiden 社区发现算法，识别功能相关的代码模块
     - 为每个社区生成业务摘要（使用 DeepSeek 模型）
     - 将社区信息整合为结构化描述，包含社区 ID、摘要和关键文件列表
   * **生成 Wiki 目录结构**:
     - 结合文件树、RepoMap 上下文和社区信息
     - 调用 LLM（Qwen Plus）生成分层的 Wiki 目录结构
     - 每个节点包含标题、ID、关联文件和子节点
4. **AI 内容生成**:
   * 遍历 Wiki 目录结构中的每个节点
   * **上下文收集**:
     - 读取节点关联的文件内容（限制长度避免超限，单文件最多 4000 字符）
     - 从代码知识图谱中提取逻辑依赖关系（调用关系）
     - 结合文件内容和依赖信息构建上下文
   * **内容生成**:
     - 调用 AI 客户端（Qwen）为每个节点生成详细描述
     - 生成 Mermaid 架构图或流程图
     - 将结果保存为独立的 JSON 文件（包含 section_id、title、breadcrumb、files、content）
5. **结果持久化**:
   * 将生成的 `wiki_structure.json` 上传至 Cloudflare R2。
   * 将各章节的详细内容 JSON 文件同步至 R2 存储（路径：`{repo_name}/{YYYYMMDD}/sections/`）。
   * 返回公网可访问的 URL 列表。
6. **清理与反馈**:
   * 清理本地克隆的仓库和临时文件。
   * 更新任务状态为"已完成"，提供 R2 公网访问 URL。

---

## 3. API 端点详解

### 3.1 任务管理

* **POST `/generate`**:
  * **功能**: 创建 Wiki 生成任务。
  * **输入**: `{ "url_link": "仓库地址" }`
  * **逻辑**: 生成唯一 UUID，初始化任务状态并推入后台异步执行。
  * **返回**: 任务 ID (`task_id`)。
* **GET `/task/{task_id}`**:
  * **功能**: 查询指定任务的状态和进度。
  * **返回**: 包含状态（pending/processing/completed/failed）、进度（0-100%）、当前步骤以及最终结果。
* **GET `/tasks`**:
  * **功能**: 列出内存中存储的所有任务记录（调试用）。
* **DELETE `/task/{task_id}`**:
  * **功能**: 删除已完成或失败的任务记录，释放内存空间。

### 3.2 系统状态

* **GET `/health`**:
  * **功能**: 健康检查，确认服务运行正常。

---

## 4. 技术实现细节

### 4.1 异步任务架构

* **FastAPI + Asyncio**: 利用 FastAPI 的异步特性，结合 `asyncio.create_task` 实现任务的即时返回与后台执行。
* **Thread Pool Executor**: 针对同步的 Git 操作（克隆）和文件 I/O 操作，使用 `loop.run_in_executor` 运行在线程池中，避免阻塞主事件循环。

### 4.2 代码知识图谱构建 (Code Knowledge Graph)

* **Tree-sitter 解析**: 使用 Tree-sitter 进行代码解析，支持多种编程语言（Python、JavaScript、TypeScript、TSX）。
* **节点提取**: 
  - 文件节点：每个代码文件作为一个节点
  - 类节点：格式为 `{file_path}:{class_name}`
  - 函数节点：格式为 `{file_path}:{function_name}`
* **边提取**:
  - `contains` 关系：文件包含类/函数
  - `calls` 关系：函数/类之间的调用关系
* **图谱存储**: 使用 NetworkX DiGraph 存储，支持后续的社区发现算法。

### 4.3 GraphRAG 社区发现

* **Leiden 算法**: 使用 Leiden 社区发现算法对代码图谱进行模块划分。
  - 将有向图转换为无向图
  - 使用 `leidenalg.ModularityVertexPartition` 进行社区划分
  - 识别功能相关的代码模块
* **社区摘要生成**:
  - 为每个社区选择代表性节点（文件和类）
  - 使用 DeepSeek 模型生成业务摘要（限制在 100 字以内）
  - 摘要重点说明社区在整个项目中的逻辑定位
* **社区信息整合**: 将社区 ID、摘要和关键文件列表整合为结构化描述，传递给 Wiki 结构生成阶段。

### 4.4 Wiki 结构生成

* **多源上下文融合**:
  - 文件树：提供项目的文件组织结构
  - RepoMap：提供代码骨架摘要
  - 社区信息：提供业务模块划分和功能描述
* **LLM 生成**: 使用 Qwen Plus 模型，结合上述上下文生成分层的 Wiki 目录结构。
* **结构规范化**: 对 LLM 返回的 JSON 进行解析和规范化，确保每个节点包含必需的字段（id、title、files、children）。

### 4.5 Wiki 内容生成

* **上下文增强**:
  - 文件内容读取：限制单文件最多 4000 字符，单章节最多 16000 字符
  - 依赖关系提取：从代码知识图谱中提取调用关系，增强上下文理解
  - 面包屑路径：为每个节点生成完整的路径信息（如 "项目概述 / 核心模块 / API 设计"）
* **内容生成**: 使用 Qwen 模型为每个节点生成详细描述和 Mermaid 图表。
* **结果存储**: 每个章节保存为独立的 JSON 文件，包含完整的元数据和生成内容。

### 4.6 AI 客户端集成 (AI Client Factory)

* 系统实现了 `AIClientFactory` 模式，支持动态切换不同的模型供应商：
  * **Qwen (默认)**: 用于生成 Wiki 内容和结构，具备较强的中文理解和代码分析能力。
  * **Qwen Plus**: 用于生成 Wiki 目录结构，提供更高质量的输出。
  * **DeepSeek**: 用于社区摘要生成，提供高性能、低成本的推理。
  * **OpenAI**: 作为备选方案。

### 4.7 存储方案 (Cloudflare R2)

* 系统使用 **Boto3 SDK** 对接 Cloudflare R2。
* **路径设计**: `{repo_name}/{YYYYMMDD}/...` 确保了不同版本和不同项目的存储隔离。
  - `wiki_structure.json`: 存储在主路径下
  - `sections/*.json`: 存储在各章节内容
* **自动清理**: 任务完成后，系统会自动执行 `shutil.rmtree` 和 `unlink` 清理容器内的临时文件，保证轻量化运行。

---

## 5. 未来优化方案 (Roadmap)

根据 RAG（检索增强生成）优化路线，未来 API 将引入以下改进：

1. **混合检索**: 引入 BM25 + 向量检索，提升对代码符号和特定术语的召回准确率。
2. **重排机制 (Reranker)**: 在生成 Wiki 内容前，对检索到的上下文进行 Cross-Encoder 重排。
3. **领域感知切分**: 针对不同文件类型（如 `.py` 采用 AST 切分，`.md` 采用标题感知切分）优化生成质量。
4. **持久化任务队列**: 将目前的内存 `tasks_store` 迁移至 Redis，支持服务重启后的任务恢复。
5. **并发限制**: 引入信号量或 Celery 队列，防止大量并发任务导致 AI Token 熔断或磁盘占满。
6. **代码知识图谱优化**: 
   - 增强调用关系的准确性（解决同名函数歧义问题）
   - 支持导入关系的完整解析
   - 添加类型信息到图谱节点
7. **社区发现优化**:
   - 支持多层次的社区划分
   - 优化社区摘要的质量和相关性
   - 引入社区间的依赖关系分析

## RAG 问答工作流优化方案（按实施优先级）

> 目标：在不依赖过于昂贵/超大模型的前提下，系统性提升问答“可检索、可排序、可引用、可验证”。本方案不修改现有代码逻辑，而是提供清晰的实施顺序与落地要点，便于逐步评估与替换现有节点。

---

### 一、实施优先级（从高到低）

1) 混合检索（稀疏+稠密）与 MMR 去冗/多样性
2) 轻量重排（Cross-Encoder reranker）
3) 上下文组装与提示词升级（结构化输出+强引用+拒答）
4) 领域感知切分（文档：标题感知；代码：AST/函数级）
5) 查询扩展（多查询改写 + HyDE 检索摘要）
6) 嵌入与索引的可选升级（维持轻量或本地化）
7) 评估与可观测性闭环（A/B + 指标面板）

---

### 二、端到端流程图（概念）

查询 → 查询扩展(Multi-Query/HyDE，可选) → 稀疏检索(BM25) + 稠密检索(FAISS) → 分数融合 → MMR 选集(去冗/多样性) → 轻量重排(Cross-Encoder) → 上下文组装(合并同源/压缩/编号[Sx]) → 结构化提示 → 生成答案(含引用与拒答策略) → 日志与评估闭环

---

### 三、各环节详细方案

#### 1) ~~混合检索 + MMR（最优先、最高性价比）~~  已经初步实现

- 目标：显著提升召回率与鲁棒性，尤其对精确术语/符号名敏感场景。
- 做法：
- 稀疏检索（BM25 或等价）与稠密检索（现有 FAISS 向量）并行召回候选（例如各取 top 100）。
- 分数归一与加权融合：`final_score = 0.6 * dense + 0.4 * sparse`（初值，可 A/B）。
- 多样性选择（MMR/BMMR）：在候选中选取 10–12 个上下文单元，既相关又互异，降低信息重复。
- 参数建议：
- 候选池：50–100；MMR 选取：10–12；MMR λ=0.5 起步。
- 类型路由：如果 Query 命中明显代码线索（函数/类/文件/报错），提高 code 类候选的权重或优先检索。

#### 2) 轻量重排（Cross-Encoder）

- 目标：把“真正最相关”的片段排到前面，提升答案精准度。
- 模型建议（中文/多语，资源可控）：`bge-reranker-base-v2` 或 `bce-reranker-base`。
- 策略：对融合+MMR 得到的 10–20 个候选做重排，保留前 8–12 个。
- 细节：同源（同文件/同标题块）片段尽量合并，避免上下文碎片化。

#### 3) 上下文组装与提示词升级

- 目标：降低噪音、增强可读性与可验证性，让模型“只能根据证据说话”。
- 上下文组装规则：
- 统一编号与头部信息：`[S{idx}] 类型:{kb_category} | 来源:{source} | 标题:{heading_path}`；正文为“精选要点句/段”。
- 合并同源片段；句级去重；控制总窗口（如 1200–1800 tokens）。
- 排序策略：按重排分数 + 结构（代码优先或按 query 类型路由）。
- 结构化回答提示（建议替换现有“仅直接回答”的提示）：

```

你是严谨的中文技术助手。只能使用给定的上下文作答，不得凭空扩展。

- 若上下文不足以回答，请明确指出缺失信息并停止推测。

- 回答必须中文，客观、简洁、可执行。

- 对每条关键结论添加引用标注，如 [S1] [S3]（对应上下文片段编号）。

- 若存在冲突信息，优先代码，其次文档；显式说明冲突与取舍依据。


请用如下结构输出：

1) 摘要（≤3句）

2) 关键要点（分点列出，每点末尾标注引用）

3) 操作建议/风险（可选）

4) 参考来源（列出用到的 [Sx] -> 类型|来源|标题）


<上下文>

{context}

</上下文>


<问题>

{question}

</问题>

```

#### 4) 领域感知切分（替代统一 2000/200）

- 文档类（text）：
- “标题感知 + 句子窗”混合：优先按 H1/H2… 标题块，再在块内按句子窗 600–900 tokens，overlap 80–120。
- 保留 `heading_path` 元数据（如 `章/节/小节`）。列表/代码块/表格尽量不截断。
- 代码类（code）：
- AST/函数/类为首要边界；过长函数再按语句/注释分段，目标 256–512 tokens，overlap 32–64。

#### 5) 查询扩展（轻量）

- 多查询改写（2–3 条）示例提示：

```

请基于下列用户问题，生成3个语义不同但等价的中文检索查询。

- 要求：每个≤20字，突出关键实体/函数名/文件名/配置项等。

- 输出JSON数组，仅包含字符串。

用户问题：{question}

```

- HyDE（检索摘要，≤120 字）示例提示：

```

请基于下列问题，生成一段“可能的专业性回答摘要”（≤120字），

仅用于检索线索，不要求完全正确，但需覆盖关键词与要点：

问题：{question}

```

- 用法：扩展查询与 HyDE 摘要均走一遍稠密检索，结果与原始查询候选合并后做融合与 MMR。

#### 6) 嵌入与索引（可选升级，保持轻量）

- 现状保持：OpenAI `text-embedding-3-small`（最小改动、表现稳健）。
- 本地化替代（可评估）：`bge-m3`（多语/中文强），索引用 FAISS IVFFlat/HNSW；维持 `code`/`text` 分库。

#### 7) 评估与可观测性闭环

- 检索侧：Recall@k、MRR、NDCG、去重率、多样性（source 覆盖率）。
- 生成侧：Faithfulness（引用对齐度）、支持度（覆盖用到的 [Sx] 占比）、拒答合理率。
- 日志建议：原始 query、扩展 queries、HyDE 摘要、稀疏/稠密候选与分数、融合得分、MMR 选集、重排前后顺序、上下文 token 数、答案与引用映射。
- 小型黄金集（10–50 问）：每次调参后自动评估与对比（A/B）。

### 五、参数与默认值（初版建议）

- 融合权重：`dense 0.6 / sparse 0.4`；候选池 50–100。
- MMR：λ=0.5，选取 10–12。
- 重排：`bge-reranker-base-v2`，batch=16，最终保留 8–12。
- 上下文预算：总 1200–1800 tokens；单源单元 ≤ 350 tokens。
- 切分：
- 文档 600–900 tokens，overlap 80–120；标题感知；不截断列表/代码块/表格。
- 代码 256–512 tokens，overlap 32–64；AST/函数级边界优先。

---

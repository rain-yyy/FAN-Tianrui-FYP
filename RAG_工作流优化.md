## RAG 问答工作流优化方案（按实施优先级）

> 目标：在不依赖过于昂贵/超大模型的前提下，系统性提升问答“可检索、可排序、可引用、可验证”。本方案不修改现有代码逻辑，而是提供清晰的实施顺序与落地要点，便于逐步评估与替换现有节点。

---

### 一、实施优先级（从高到低）

1) 混合检索（稀疏+稠密）与 MMR 去冗/多样性
2) 轻量重排（Cross-Encoder reranker）
3) 上下文组装与提示词升级（结构化输出+强引用+拒答）
4) 领域感知切分（文档：标题感知；代码：AST/函数级）
5) 查询扩展（多查询改写 + HyDE 检索摘要）
6) 嵌入与索引的可选升级（维持轻量或本地化）
7) 评估与可观测性闭环（A/B + 指标面板）

---

### 二、端到端流程图（概念）

查询 → 查询扩展(Multi-Query/HyDE，可选) → 稀疏检索(BM25) + 稠密检索(FAISS) → 分数融合 → MMR 选集(去冗/多样性) → 轻量重排(Cross-Encoder) → 上下文组装(合并同源/压缩/编号[Sx]) → 结构化提示 → 生成答案(含引用与拒答策略) → 日志与评估闭环

---

### 三、各环节详细方案

#### 1) 混合检索 + MMR（最优先、最高性价比）
- 目标：显著提升召回率与鲁棒性，尤其对精确术语/符号名敏感场景。
- 做法：
  - 稀疏检索（BM25 或等价）与稠密检索（现有 FAISS 向量）并行召回候选（例如各取 top 100）。
  - 分数归一与加权融合：`final_score = 0.6 * dense + 0.4 * sparse`（初值，可 A/B）。
  - 多样性选择（MMR/BMMR）：在候选中选取 10–12 个上下文单元，既相关又互异，降低信息重复。
- 参数建议：
  - 候选池：50–100；MMR 选取：10–12；MMR λ=0.5 起步。
  - 类型路由：如果 Query 命中明显代码线索（函数/类/文件/报错），提高 code 类候选的权重或优先检索。

#### 2) 轻量重排（Cross-Encoder）
- 目标：把“真正最相关”的片段排到前面，提升答案精准度。
- 模型建议（中文/多语，资源可控）：`bge-reranker-base-v2` 或 `bce-reranker-base`。
- 策略：对融合+MMR 得到的 10–20 个候选做重排，保留前 8–12 个。
- 细节：同源（同文件/同标题块）片段尽量合并，避免上下文碎片化。

#### 3) 上下文组装与提示词升级
- 目标：降低噪音、增强可读性与可验证性，让模型“只能根据证据说话”。
- 上下文组装规则：
  - 统一编号与头部信息：`[S{idx}] 类型:{kb_category} | 来源:{source} | 标题:{heading_path}`；正文为“精选要点句/段”。
  - 合并同源片段；句级去重；控制总窗口（如 1200–1800 tokens）。
  - 排序策略：按重排分数 + 结构（代码优先或按 query 类型路由）。
- 结构化回答提示（建议替换现有“仅直接回答”的提示）：

```
你是严谨的中文技术助手。只能使用给定的上下文作答，不得凭空扩展。
- 若上下文不足以回答，请明确指出缺失信息并停止推测。
- 回答必须中文，客观、简洁、可执行。
- 对每条关键结论添加引用标注，如 [S1] [S3]（对应上下文片段编号）。
- 若存在冲突信息，优先代码，其次文档；显式说明冲突与取舍依据。

请用如下结构输出：
1) 摘要（≤3句）
2) 关键要点（分点列出，每点末尾标注引用）
3) 操作建议/风险（可选）
4) 参考来源（列出用到的 [Sx] -> 类型|来源|标题）

<上下文>
{context}
</上下文>

<问题>
{question}
</问题>
```

#### 4) 领域感知切分（替代统一 2000/200）
- 文档类（text）：
  - “标题感知 + 句子窗”混合：优先按 H1/H2… 标题块，再在块内按句子窗 600–900 tokens，overlap 80–120。
  - 保留 `heading_path` 元数据（如 `章/节/小节`）。列表/代码块/表格尽量不截断。
- 代码类（code）：
  - AST/函数/类为首要边界；过长函数再按语句/注释分段，目标 256–512 tokens，overlap 32–64。

#### 5) 查询扩展（轻量）
- 多查询改写（2–3 条）示例提示：
```
请基于下列用户问题，生成3个语义不同但等价的中文检索查询。
- 要求：每个≤20字，突出关键实体/函数名/文件名/配置项等。
- 输出JSON数组，仅包含字符串。
用户问题：{question}
```
- HyDE（检索摘要，≤120 字）示例提示：
```
请基于下列问题，生成一段“可能的专业性回答摘要”（≤120字），
仅用于检索线索，不要求完全正确，但需覆盖关键词与要点：
问题：{question}
```
- 用法：扩展查询与 HyDE 摘要均走一遍稠密检索，结果与原始查询候选合并后做融合与 MMR。

#### 6) 嵌入与索引（可选升级，保持轻量）
- 现状保持：OpenAI `text-embedding-3-small`（最小改动、表现稳健）。
- 本地化替代（可评估）：`bge-m3`（多语/中文强），索引用 FAISS IVFFlat/HNSW；维持 `code`/`text` 分库。

#### 7) 评估与可观测性闭环
- 检索侧：Recall@k、MRR、NDCG、去重率、多样性（source 覆盖率）。
- 生成侧：Faithfulness（引用对齐度）、支持度（覆盖用到的 [Sx] 占比）、拒答合理率。
- 日志建议：原始 query、扩展 queries、HyDE 摘要、稀疏/稠密候选与分数、融合得分、MMR 选集、重排前后顺序、上下文 token 数、答案与引用映射。
- 小型黄金集（10–50 问）：每次调参后自动评估与对比（A/B）。

---

### 四、与当前代码的对接点（不立刻改代码，仅标注位置）

- 检索融合/去冗/重排注入点：
  - `RAG对话.py` 中集中检索逻辑：`_answer_with_stores()` 里按类别 `store.similarity_search(question, k=k)` 的位置之后加入：
    - 多查询/HyDE → 稠密检索结果合并
    - 稀疏检索（BM25）结果合并
    - 分数融合 → MMR 选集 → Cross-Encoder 重排 → 最终上下文集合

- 上下文组装与提示：
  - `RAG对话.py` 里的 `_format_documents()` 可替换为“带 [Sx] 头、同源合并、句级去重、长度裁剪”的实现；
  - `prompts/prompts.py` 的 `RAG_CHAT_PROMPT` 建议替换为“结构化回答 + 引用 + 拒答”的模板。

- 切分差异化：
  - `document_splitter.py` 现为统一 `RecursiveCharacterTextSplitter(2000/200)`；建议根据文件类别分别切分（文档/代码），并为文档保留 `heading_path`，为代码保留 `symbol_name/module` 等元数据。

- 嵌入与加载：
  - `vector_store_creator.py` 与 `knowledge_base_loader.py` 保持同一嵌入模型。若改到本地 `bge-m3`，需要二者同步。

---

### 五、参数与默认值（初版建议）

- 融合权重：`dense 0.6 / sparse 0.4`；候选池 50–100。
- MMR：λ=0.5，选取 10–12。
- 重排：`bge-reranker-base-v2`，batch=16，最终保留 8–12。
- 上下文预算：总 1200–1800 tokens；单源单元 ≤ 350 tokens。
- 切分：
  - 文档 600–900 tokens，overlap 80–120；标题感知；不截断列表/代码块/表格。
  - 代码 256–512 tokens，overlap 32–64；AST/函数级边界优先。

---

### 六、最小可行子集（MVP 两步走）

1) 加入“混合检索 + MMR + 轻量重排”，不改模型，仅改检索与排序链路。
2) 替换提示与上下文组装为“结构化 + 引用 + 拒答 + 同源合并”。

> 这两步通常即可显著提升相关性与可验证性，适合优先上线与 A/B 评估。

---

### 七、模型与资源建议（轻量为先）

- 嵌入：继续 `text-embedding-3-small`；如需本地化评估，可试 `bge-m3`。
- 重排：`bge-reranker-base-v2` 或 `bce-reranker-base`（Cross-Encoder）。
- LLM：保留 `gpt-4o-mini`；查询扩展/HyDE 如需本地化，可用 `Qwen2.5-7B-Instruct` 级别。

---

### 八、版本化与回滚建议

- 每个节点改动独立分支：`feature/rag-hybrid`、`feature/rag-rerank`、`feature/rag-context-prompt`…
- 引入黄金集与自动评估脚本，变更合入条件：相关性↑、幻觉↓、响应时间可接受。
- 预留开关：支持按配置回退到“纯向量检索 + 旧提示”的稳定基线。

---

如需，我可以基于本方案按“注入点”生成对等的替换实现（保持现有文件结构与接口），并附 A/B 评估脚本与示例黄金集模板，便于你逐步验证与合入。

